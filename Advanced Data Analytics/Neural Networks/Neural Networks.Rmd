---
title: "Neural Networks"
author: "Blake Pappas"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
bookmarks: no
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Neural Networks in R
# Load the following packages:
```{r, warning = FALSE, message = FALSE}
library(caret)
library(dplyr)
library(neuralnet)
```

# In this exercise, we use the "breast_cancer.csv" file.
# The goal is to predict the type of cancer based on characteristics of cells. 
# The "Class" variable contains cancer type. 2 means benign and 4 means malignant. 
# Split the data into 60% training and 40% testing:
```{r, warning = FALSE}
cancer = read.csv("breast_cancer.csv")

train_rows = createDataPartition(y = cancer$Class,
                                 p = 0.60, list = FALSE)

cancer = cancer %>%
  mutate(benign = ifelse(Class == 2, 1, 0),
         malignant = ifelse(Class == 4, 1, 0))

cancer_train = cancer[train_rows, ]
cancer_test = cancer[-train_rows, ]
```

# Use a "for" loop to build a series of neural network models, with increasing numbers of hidden layers (1 layer to 5 layers).
# Evaluate the performance of each model, and report the best model (i.e., the best number of hidden layers and the best accuracy).
# Keep the number of neurons at each layer constant (2 neurons each layer), the learning rate constant (set learningrate to be 0.01), and set the training epochs to be 3.
```{r, warning = FALSE}
results = data.frame()

best_accuracy = 0

best_layer = 0

for(i in 1:5) {
  
  hidden_layers = rep(2, i)
  
  # Train the Neural Network
  NN_model = neuralnet(benign + malignant ~ Clump.Thickness + Uniformity.of.Cell.Size + Uniformity.of.Cell.Shape + Marginal.Adhesion + Single.Epithelial.Cell.Size + Bare.Nuclei + Bland.Chromatin + Normal.Nucleoli + Mitoses,
                         data = cancer_train,
                         act.fct = "logistic",
                         linear.output = FALSE,
                         hidden = hidden_layers,
                         algorithm = "backprop",
                         learningrate = 0.01, 
                         rep = 3)
  
  # Make Predictions
  pred = neuralnet::compute(NN_model, cancer_test[, 1:9])$net.result
  
  # Convert to Class Labels
  outcomes = c("2", "4")
  pred_label = outcomes[max.col(pred)]
  
  # Evaluate Performance
  accuracy = confusionMatrix(factor(pred_label), factor(cancer_test$Class),
                              positive = "4")$overall[1]
  
  cm = confusionMatrix(factor(pred_label), factor(cancer_test$Class),
                        positive = "4")
  
  print(cm)
  
  # Store the Results in the Data Frame
  run = data.frame(Layers = i, Accuracy = accuracy)
  
  # Append the Each Consecutive Run's Results to the Data Frame
  results = rbind(results, run)
  
  if(accuracy > best_accuracy) {
    
    best_run = NN_model
    
    best_layer = i
    
    best_accuracy = accuracy
    
  }
}

print(results)
```